{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus1: Parallel Algorithms (Decentralized Optimization)\n",
    "\n",
    "### Name: Harman Singh Bath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Parallel/Parallel.pdf)\n",
    "\n",
    "2. Implement federated averaging or decentralized optimization.\n",
    "\n",
    "3. Plot the convergence curve. (The x-axis can be ```number of epochs``` or ```number of communication```. You must make sure the label is correct.)\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo. (If it is submitted to Google Drive or Dropbox, you must make the file open-access.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/Bonus1/Bonus1.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[ 0.03333134 -0.00899833  0.07757726  0.0988063   0.001419    0.0548428\n",
      "   0.0095346   0.01509145]]\n",
      "test std = \n",
      "[[1.06805005 1.03258155 0.86336279 0.98452403 0.91739704 1.14284902\n",
      "  0.98057207 0.91956871]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Worker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definine a Worker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# Class defining a worker node\n",
    "class Worker:\n",
    "    def __init__(self, node_name, x, y, alpha, beta, lam, scale_factor):\n",
    "        self.node_name = node_name\n",
    "        self.neighbors=[]\n",
    "        self.x = x # s x d local feature matrix\n",
    "        self.y = y # s x 1 local label matrix\n",
    "        self.s = x.shape[0] # number of local samples\n",
    "        self.d = x.shape[1] # number of features\n",
    "        self.scale_factor = scale_factor\n",
    "        self.lam = lam\n",
    "        self.v = numpy.zeros((self.d,1)) # d x 1\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(self.s)\n",
    "        self.x = self.x[rand_indices, :]\n",
    "        self.y = self.y[rand_indices, :]\n",
    "        \n",
    "        self.w = numpy.zeros((self.d,1)) # d x 1 model parameter vector\n",
    "        \n",
    "    # add neighbors\n",
    "    def add_neighbor(self, neighbor):\n",
    "        self.neighbors.append(neighbor)\n",
    "    \n",
    "    # set model parameters to latest\n",
    "    def set_param(self, w):\n",
    "        self.w = w\n",
    "        \n",
    "    # compute local loss\n",
    "    def loss(self):\n",
    "        yx = numpy.multiply(self.y, self.x) # s x d\n",
    "        yxw = numpy.dot(yx, self.w) # s x 1\n",
    "        vec1 = numpy.exp(-yxw) # s x 1\n",
    "        vec2 = numpy.log(1+vec1) # s x 1\n",
    "        return numpy.sum(vec2)\n",
    "        \n",
    "    # compute local gradient\n",
    "    def gradient(self, y, x):\n",
    "        yx = numpy.multiply(y, x) # s x d\n",
    "        yxw = numpy.dot(yx, self.w) # s x 1\n",
    "        vec1 = numpy.exp(yxw) # s x 1\n",
    "        vec2 = numpy.divide(yx, 1+vec1) # s x d\n",
    "        g = -numpy.sum(vec2, axis=0).reshape(self.d, 1) # d x 1\n",
    "        return g\n",
    "    \n",
    "    def agd(self, g):\n",
    "        self.v *= self.beta\n",
    "        self.v += g\n",
    "        self.w -= self.alpha*self.v\n",
    "        \n",
    "    def objective(self, lam, loss):\n",
    "        reg = lam/2 * numpy.sum(self.w*self.w)\n",
    "        self.obj = loss/self.s + reg\n",
    "        return self.obj\n",
    "        \n",
    "    def client_update(self):\n",
    "        g = self.gradient(self.y, self.x)\n",
    "\n",
    "        for neighbor in self.neighbors:\n",
    "            scaled_weights = self.scale_factor * neighbor.w\n",
    "            self.w += scaled_weights\n",
    "        self.w /= 1+(self.scale_factor*len(self.neighbors))\n",
    "        self.agd(g)\n",
    "        local_loss =self.loss()\n",
    "        return self.w, local_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simulation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def create_workers(m,x,y,alpha,beta,lam,scale_factor):\n",
    "    n,d = x.shape\n",
    "    s = math.floor(n/m)\n",
    "    \n",
    "    workers = []\n",
    "    for i in range(m):\n",
    "        indices = list(range(i * s, (i+1) * s))\n",
    "        workers.append(Worker(\"worker_\"+str(i+1), x[indices,:], y[indices,:], alpha, beta, lam, scale_factor))\n",
    "    return workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(weights, losses):\n",
    "    w = numpy.mean(numpy.array(weights), axis=0)\n",
    "    loss = sum(losses)\n",
    "    return w, loss\n",
    "\n",
    "def objective(lam, w, loss, n):\n",
    "    reg = lam/2 * numpy.sum(w*w)\n",
    "    obj = loss/n + reg\n",
    "    return obj\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
